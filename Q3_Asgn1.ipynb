{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Q1 json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to open json file\n",
    "f=open('neighbor-districts-modified.json')\n",
    "# this function basically stores json type files into python dictionary\n",
    "dist_modified=json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get district names and ids form Q1 json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_list_from_json=[]\n",
    "for key in dist_modified:\n",
    "    district_list_from_json.append(key)\n",
    "district_list_from_json=np.array(district_list_from_json)\n",
    "district_list_from_json.sort()\n",
    "\n",
    "state_district_codes=[]\n",
    "for i in range(len(district_list_from_json)):\n",
    "    state_district_codes.append(district_list_from_json[i].split('/')[1])\n",
    "\n",
    "# district names - sample entry: churu\n",
    "district_names_from_json=[] \n",
    "\n",
    "# district ids - sample entry: RJ_Churu\n",
    "district_ids_from_json=[]\n",
    "\n",
    "#use split() function and specify the separator '/' . Remember default seperator is whitspace\n",
    "for i in range(len(district_list_from_json)):\n",
    "    district_names_from_json.append(district_list_from_json[i].split(\"/\")[0])\n",
    "    district_ids_from_json.append(district_list_from_json[i].split(\"/\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_ids_list={}\n",
    "for i in range(len(district_names_from_json)):\n",
    "    district_ids_list[district_ids_from_json[i]]=district_names_from_json[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating time ids\n",
    "- [x] Start date: 2020-03-15\n",
    "- [x] End date: 2021-08-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaries for mapping dates to time ids\n",
    "# eg. for 2020-3-15, time_id_week is 1, time_id_month is 1, time_id_ is 1\n",
    "\n",
    "time_id_week = {}\n",
    "time_id_month = {}\n",
    "time_id_overall = {}\n",
    "\n",
    "date=datetime.date(2020,3,15)\n",
    "day=1\n",
    "\n",
    "while True:\n",
    "    # basically to cover overlapping weeks this part needs to be changed.\n",
    "    # for now we are proceeding. but change week ids according above definition of 7-DMA\n",
    "    time_id_week[str(date)]=int(np.ceil(day/7))\n",
    "    \n",
    "    if str(date)[0:4]=='2020':\n",
    "        if int(str(date)[8:10]) <15:\n",
    "            time_id_month[str(date)]=int(str(date)[5:7])-3\n",
    "        else:\n",
    "            time_id_month[str(date)]=int(str(date)[5:7])-2\n",
    "    else:\n",
    "        if int(str(date)[8:10]) <15:\n",
    "            time_id_month[str(date)]=int(str(date)[5:7])+9\n",
    "        else:\n",
    "            time_id_month[str(date)]=int(str(date)[5:7])+10\n",
    "\n",
    "    time_id_overall[str(date)]=1\n",
    "    \n",
    "    if date==datetime.date(2021,8,14):\n",
    "        break\n",
    "    day=day+1\n",
    "    date=date+datetime.timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read districts csv for cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Date', 'State', 'District', 'Confirmed']\n",
    "data_csv=pd.read_csv('districts.csv',usecols=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv=data_csv.sort_values(['District','Date'])\n",
    "data_csv.reset_index(inplace=True,drop=True) #should not forget it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting intersection district names from districts csv and modified json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_names_from_cases=[]\n",
    "district_ids_from_cases=[]\n",
    "district_uniques=np.array(np.unique(data_csv['District']))\n",
    "for i in range(len(district_ids_from_json)):\n",
    "    a=district_ids_from_json[i].split('_')\n",
    "    for j in range(len(district_uniques)):\n",
    "        if district_uniques[j]==a[1]:\n",
    "            district_ids_from_cases.append(district_ids_from_json[i])\n",
    "            district_names_from_cases.append(a[1])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these many districts are there in districts.csv = 648\n",
      "these many districts are in both files intersection = 622\n"
     ]
    }
   ],
   "source": [
    "print(\"these many districts are there in districts.csv =\",len(district_uniques)+5) # for those common five names\n",
    "print(\"these many districts are in both files intersection =\" ,len(district_ids_from_cases)) # though they are included in here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------To check whether things are consistent------\n",
      "MH_Beed\n",
      "Beed\n"
     ]
    }
   ],
   "source": [
    "print('-------To check whether things are consistent------')\n",
    "print(district_ids_from_cases[67])\n",
    "print(district_names_from_cases[67])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get daily cases from cummulative confirmed cases\n",
    "- [x] Formula use: cases in present day = present day cases - previous day cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/sunild/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1765: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.6 s, sys: 3.34 ms, total: 20.6 s\n",
      "Wall time: 20.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# getting daily cases\n",
    "data_csv['Daily Cases']=np.nan\n",
    "for i in range(len(district_names_from_cases)):\n",
    "    foo_df = data_csv[data_csv['District']==district_names_from_cases[i]]\n",
    "    foo_cases = foo_df.iloc[0,3]\n",
    "    foo_df['Daily Cases']=foo_df['Confirmed'].diff()\n",
    "    foo_df.iloc[0,4]=foo_cases\n",
    "    data_csv.loc[data_csv['District']==district_names_from_cases[i],'Daily Cases']=foo_df['Daily Cases']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### these many rows can be dropped related to districts that are not in intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               0\n",
       "State              0\n",
       "District           0\n",
       "Confirmed          0\n",
       "Daily Cases    17209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.isnull().sum() #these many interies are NaN for those districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Giving week and month ID to each date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_in_raw=np.unique(data_csv['Date']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 7.92 ms, total: 16.3 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#give week and month id to dates\n",
    "data_csv['Week ID']=np.nan\n",
    "data_csv['Month ID']=np.nan\n",
    "for date in time_id_week:\n",
    "    if dates_in_raw.count(date)>0:\n",
    "        data_csv.loc[data_csv['Date']==date,'Week ID']=time_id_week[date]\n",
    "        data_csv.loc[data_csv['Date']==date,'Month ID']=time_id_month[date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows with out of range dates\n",
    "- [x] These many dates are after end date: 2021-08-14 (for all districts in intersection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date               0\n",
       "State              0\n",
       "District           0\n",
       "Confirmed          0\n",
       "Daily Cases        0\n",
       "Week ID        11818\n",
       "Month ID       11818\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_csv.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For week wise cases for all districts in intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- [x] Delhi also can be included but I dont't think I should write special code just to include one District."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.7 s, sys: 40 ms, total: 29.8 s\n",
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "no_of_weeks=list(time_id_week.values())[-1]\n",
    "districtid=[]\n",
    "weekid=[]\n",
    "cases=[]\n",
    "for i in range(len(district_names_from_cases)): # if delhi etc are not there just \n",
    "    foo=data_csv[data_csv['District']==district_names_from_cases[i]]\n",
    "    for j in range(no_of_weeks):\n",
    "        districtid.append(district_ids_from_cases[i])\n",
    "        weekid.append(j+1)\n",
    "        cases.append(foo[foo['Week ID']==j+1]['Daily Cases'].sum())\n",
    "        \n",
    "week_df=pd.DataFrame({'districtid':districtid,'weekid':weekid,'cases':cases})\n",
    "week_df.sort_values(\"districtid\",axis=0,ascending=True, inplace=True, kind='mergesort')\n",
    "week_df.reset_index(inplace=True,drop=True)\n",
    "week_df.to_csv('cases-week.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For month wise cases for all districts in intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.9 s, sys: 12 ms, total: 12.9 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "no_of_months=list(time_id_month.values())[-1]\n",
    "districtid=[]\n",
    "monthid=[]\n",
    "cases=[]\n",
    "for i in range(len(district_names_from_cases)): # if delhi etc are not there just \n",
    "    data_foo=data_csv[data_csv['District']==district_names_from_cases[i]]\n",
    "    for j in range(no_of_months):\n",
    "        districtid.append(district_ids_from_cases[i])\n",
    "        monthid.append(j+1)\n",
    "        cases.append(data_foo[data_foo['Month ID']==j+1]['Daily Cases'].sum())\n",
    "        \n",
    "month_df=pd.DataFrame({'districtid':districtid,'monthid':monthid,'cases':cases})\n",
    "month_df.sort_values(\"districtid\",axis=0,ascending=True, inplace=True, kind='mergesort')\n",
    "month_df.reset_index(inplace=True,drop=True)\n",
    "month_df.to_csv('cases-month.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overall cases for all districts in intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.81 s, sys: 0 ns, total: 8.81 s\n",
      "Wall time: 8.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "districtid=[]\n",
    "overallid=[]\n",
    "cases=[]\n",
    "\n",
    "for i in range(len(district_names_from_cases)):\n",
    "    #for j in range(len(np.unique(raw['Week ID']))):\n",
    "    districtid.append(district_ids_from_cases[i])\n",
    "    overallid.append(1)\n",
    "    cases.append(data_csv[data_csv['District']==district_names_from_cases[i]]['Daily Cases'].sum())\n",
    "        \n",
    "overall_df=pd.DataFrame({'districtid':districtid,'overallid':overallid,'cases':cases})\n",
    "overall_df.sort_values(\"districtid\",axis=0,ascending=True, inplace=True, kind='mergesort')\n",
    "overall_df.reset_index(inplace=True,drop=True)\n",
    "overall_df.to_csv('cases-overall.csv',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
